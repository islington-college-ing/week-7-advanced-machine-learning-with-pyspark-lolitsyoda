{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRLHWUIzdikR",
        "outputId": "e84f3dc0-9fb3-4b8a-c055-d4b327d1bfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        " .appName(\"CreditCardFraudDetection\") \\\n",
        " .getOrCreate()\n",
        "# Load the dataset\n",
        "!wget https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv\n",
        "data = spark.read.csv('creditcard.csv', header=True, inferSchema=True)\n",
        "# Display the schema and a few rows of data\n",
        "data.printSchema()\n",
        "data.show(5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXPM9f6IdmCz",
        "outputId": "09e6a9e9-2e8a-47f7-8a96-18647ae9ed17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-20 01:59:26--  https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102634230 (98M) [text/plain]\n",
            "Saving to: ‘creditcard.csv’\n",
            "\n",
            "creditcard.csv      100%[===================>]  97.88M   207MB/s    in 0.5s    \n",
            "\n",
            "2024-08-20 01:59:34 (207 MB/s) - ‘creditcard.csv’ saved [102634230/102634230]\n",
            "\n",
            "root\n",
            " |-- Time: double (nullable = true)\n",
            " |-- V1: double (nullable = true)\n",
            " |-- V2: double (nullable = true)\n",
            " |-- V3: double (nullable = true)\n",
            " |-- V4: double (nullable = true)\n",
            " |-- V5: double (nullable = true)\n",
            " |-- V6: double (nullable = true)\n",
            " |-- V7: double (nullable = true)\n",
            " |-- V8: double (nullable = true)\n",
            " |-- V9: double (nullable = true)\n",
            " |-- V10: double (nullable = true)\n",
            " |-- V11: double (nullable = true)\n",
            " |-- V12: double (nullable = true)\n",
            " |-- V13: double (nullable = true)\n",
            " |-- V14: double (nullable = true)\n",
            " |-- V15: double (nullable = true)\n",
            " |-- V16: double (nullable = true)\n",
            " |-- V17: double (nullable = true)\n",
            " |-- V18: double (nullable = true)\n",
            " |-- V19: double (nullable = true)\n",
            " |-- V20: double (nullable = true)\n",
            " |-- V21: double (nullable = true)\n",
            " |-- V22: double (nullable = true)\n",
            " |-- V23: double (nullable = true)\n",
            " |-- V24: double (nullable = true)\n",
            " |-- V25: double (nullable = true)\n",
            " |-- V26: double (nullable = true)\n",
            " |-- V27: double (nullable = true)\n",
            " |-- V28: double (nullable = true)\n",
            " |-- Amount: double (nullable = true)\n",
            " |-- Class: integer (nullable = true)\n",
            "\n",
            "+----+------------+------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------+-----+\n",
            "|Time|          V1|          V2|         V3|          V4|          V5|          V6|          V7|          V8|          V9|         V10|         V11|         V12|         V13|         V14|         V15|         V16|         V17|         V18|         V19|         V20|         V21|         V22|         V23|         V24|         V25|         V26|         V27|         V28|Amount|Class|\n",
            "+----+------------+------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------+-----+\n",
            "| 0.0|-1.359807134|-0.072781173|2.536346738| 1.378155224| -0.33832077| 0.462387778| 0.239598554| 0.098697901|  0.36378697| 0.090794172|-0.551599533|-0.617800856|-0.991389847|-0.311169354| 1.468176972|-0.470400525| 0.207971242|  0.02579058|  0.40399296| 0.251412098|-0.018306778| 0.277837576| -0.11047391| 0.066928075| 0.128539358|-0.189114844| 0.133558377|-0.021053053|149.62|    0|\n",
            "| 0.0| 1.191857111| 0.266150712|0.166480113| 0.448154078| 0.060017649|-0.082360809|-0.078802983| 0.085101655|-0.255425128|-0.166974414| 1.612726661| 1.065235311| 0.489095016|-0.143772296| 0.635558093| 0.463917041|-0.114804663| -0.18336127|-0.145783041|-0.069083135|-0.225775248|-0.638671953| 0.101288021|-0.339846476| 0.167170404| 0.125894532|-0.008983099| 0.014724169|  2.69|    0|\n",
            "| 1.0|-1.358354062|-1.340163075|1.773209343| 0.379779593|-0.503198133| 1.800499381| 0.791460956| 0.247675787|-1.514654323| 0.207642865| 0.624501459| 0.066083685| 0.717292731|-0.165945923| 2.345864949|-2.890083194| 1.109969379|-0.121359313|-2.261857095| 0.524979725| 0.247998153| 0.771679402| 0.909412262|-0.689280956|-0.327641834|-0.139096572|-0.055352794|-0.059751841|378.66|    0|\n",
            "| 1.0|-0.966271712|-0.185226008| 1.79299334|-0.863291275| -0.01030888| 1.247203168|  0.23760894| 0.377435875|-1.387024063|-0.054951922|-0.226487264| 0.178228226|  0.50775687|-0.287923745|-0.631418118|-1.059647245|-0.684092786| 1.965775003| -1.23262197|-0.208037781|-0.108300452| 0.005273597|-0.190320519|-1.175575332| 0.647376035|-0.221928844| 0.062722849| 0.061457629| 123.5|    0|\n",
            "| 2.0|-1.158233093| 0.877736755|1.548717847| 0.403033934|-0.407193377| 0.095921462| 0.592940745|-0.270532677| 0.817739308| 0.753074432|-0.822842878|  0.53819555| 1.345851593|-1.119669835|  0.17512113|-0.451449183|-0.237033239|-0.038194787| 0.803486925|  0.40854236|-0.009430697| 0.798278495| -0.13745808| 0.141266984|-0.206009588| 0.502292224|  0.21942223| 0.215153147| 69.99|    0|\n",
            "+----+------------+------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col, when\n",
        "# Select features and label\n",
        "feature_columns = data.columns[:-1] # All columns except the last one, which is the label\n",
        "assembler = VectorAssembler(inputCols=feature_columns,\n",
        "outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "# Rename the label column\n",
        "final_data = data.select(col(\"features\"),\n",
        "col(\"Class\").alias(\"label\"))\n",
        "# Display the transformed data\n",
        "final_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgm2_ZVsegii",
        "outputId": "ce66dfb6-2642-46e5-fc6e-f3af05955d54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[0.0,-1.359807134...|    0|\n",
            "|[0.0,1.191857111,...|    0|\n",
            "|[1.0,-1.358354062...|    0|\n",
            "|[1.0,-0.966271712...|    0|\n",
            "|[2.0,-1.158233093...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
        "# Train the RandomForest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
        "model = rf.fit(train_data)\n",
        "# Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "predictions.show(5)\n",
        "# Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",\n",
        "metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "print(f\"Model ROC-AUC: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRmgGSy_glaE",
        "outputId": "2afd67f9-1e9f-4b13-aac4-4c68229bb85f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|[0.0,-1.359807134...|    0|[9.99760591824497...|[0.99976059182449...|       0.0|\n",
            "|[1.0,-0.966271712...|    0|[9.99760591824497...|[0.99976059182449...|       0.0|\n",
            "|[2.0,-1.158233093...|    0|[9.99760591824497...|[0.99976059182449...|       0.0|\n",
            "|[7.0,-0.894286082...|    0|[9.99760591824497...|[0.99976059182449...|       0.0|\n",
            "|[7.0,-0.644269442...|    0|[9.99658805971474...|[0.99965880597147...|       0.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Model ROC-AUC: 0.9591584218905982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
        "# Train the RandomForest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
        "model = rf.fit(train_data)\n",
        "# Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "predictions.show(5)\n",
        "# Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",\n",
        "metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "print(f\"Model ROC-AUC: {roc_auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDUwGfjbg2MI",
        "outputId": "7daf8324-39c0-49ff-cad9-55ec3e37c878"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|[0.0,-1.359807134...|    0|[9.99745421906730...|[0.99974542190673...|       0.0|\n",
            "|[0.0,1.191857111,...|    0|[9.99745421906730...|[0.99974542190673...|       0.0|\n",
            "|[4.0,1.229657635,...|    0|[9.99745421906730...|[0.99974542190673...|       0.0|\n",
            "|[10.0,1.249998742...|    0|[9.99745421906730...|[0.99974542190673...|       0.0|\n",
            "|[12.0,-2.79185476...|    0|[9.98521283411877...|[0.99852128341187...|       0.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Model ROC-AUC: 0.9394669543552974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "# Create a sample new example with the same structure as the features in the dataset\n",
        "new_example = spark.createDataFrame([\n",
        " (0, Vectors.dense([0.0, 0.0, 1.0, 0.0, 2.0, 0.0, -1.0, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5,\n",
        "0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 1.0]))\n",
        "], [\"label\", \"features\"])\n",
        "# Use the trained model to predict the label for this new example\n",
        "sample_prediction = model.transform(new_example)\n",
        "sample_prediction.show(truncate=False)\n",
        "# Extract the prediction and probability\n",
        "sample_prediction.select(\"features\", \"prediction\", \"probability\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4DjazRwhJQy",
        "outputId": "edae5afd-bb52-4e5b-e955-21beaf095528"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------+-----------------------------------------+----------+\n",
            "|label|features                                                                                                                             |rawPrediction                            |probability                              |prediction|\n",
            "+-----+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------+-----------------------------------------+----------+\n",
            "|0    |[0.0,0.0,1.0,0.0,2.0,0.0,-1.0,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,1.0]|[9.997454219067306,0.0025457809326931906]|[0.9997454219067308,2.545780932693191E-4]|0.0       |\n",
            "+-----+-------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------+-----------------------------------------+----------+\n",
            "\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+----------+-----------------------------------------+\n",
            "|features                                                                                                                             |prediction|probability                              |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+----------+-----------------------------------------+\n",
            "|[0.0,0.0,1.0,0.0,2.0,0.0,-1.0,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,0.5,-0.5,1.0]|0.0       |[0.9997454219067308,2.545780932693191E-4]|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+----------+-----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TcdI8yY_hgDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}